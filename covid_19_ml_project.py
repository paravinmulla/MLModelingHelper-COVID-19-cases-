# -*- coding: utf-8 -*-
"""COVID-19_ML_PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D4UYsIrih2MDLX28nae3wm57rZ1pVhxw

**INTRODUCTION**

The proposal is significant as accurate disease prediction allows for proactive and targeted medical interventions, enhancing treatment effectiveness. Predictive models reduce healthcare burden by enabling early identification of at-risk individuals, facilitating timely interventions and resource allocation. The impact lies in improved screening efficiency, early diagnosis, and optimized healthcare resource utilization. Potential gaps may arise in data quality or model generalization, requiring ongoing refinement to address emerging healthcare challenges and ensure adaptability to new diseases.
"""

import numpy as np
import pandas as pd
import seaborn as sns

df=pd.read_csv('/content/corona_tested_006.csv')

df.head(5)

df.shape

df.isnull().sum()

df["Test_date"]=pd.to_datetime(df["Test_date"])

df.head(5)

df["month"]=df["Test_date"].dt.month

df["month"]

"""**  DATA** **CLEANING**

Identify and replace "None" values with the mode
"""

df['Cough_symptoms'].value_counts()

df["Cough_symptoms"].replace("None", df["Cough_symptoms"].mode()[0], inplace=True)

df['Cough_symptoms'].value_counts()

df['Cough_symptoms']=df['Cough_symptoms'].apply(lambda x: 'false' if x==False else x)
df['Cough_symptoms']=df['Cough_symptoms'].apply(lambda x: 'true' if x==True else x)

df['Cough_symptoms']=df['Cough_symptoms'].apply(lambda x: x.lower() if isinstance(x,str) else x)

df['Cough_symptoms'].value_counts()

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(x='Cough_symptoms', data=df)
plt.show()

df['Fever'].value_counts()

df["Fever"].replace("None", df["Fever"].mode()[0], inplace=True)

df['Fever'].value_counts()

df['Fever']=df['Fever'].apply(lambda x: 'false' if x==False else x)
df['Fever']=df['Fever'].apply(lambda x: 'true' if x==True else x)

df['Fever']=df['Fever'].apply(lambda x: x.lower() if isinstance(x,str) else x)

df['Fever'].value_counts()

sns.countplot(x='Fever', data=df)
plt.show()

df['Sore_throat'].value_counts()

df["Sore_throat"].replace("None", df["Sore_throat"].mode()[0], inplace=True)

df['Sore_throat']=df['Sore_throat'].apply(lambda x: 'false' if x==False else x)
df['Sore_throat']=df['Sore_throat'].apply(lambda x: 'true' if x==True else x)

df['Sore_throat']=df['Sore_throat'].apply(lambda x: x.lower() if isinstance(x,str) else x)

df['Sore_throat'].value_counts()

sns.countplot(x='Sore_throat', data=df)
plt.show()

df['Shortness_of_breath'].value_counts()

df["Shortness_of_breath"].replace("None", df["Shortness_of_breath"].mode()[0], inplace=True)

df['Shortness_of_breath']=df['Shortness_of_breath'].apply(lambda x: 'false' if x==False else x)
df['Shortness_of_breath']=df['Shortness_of_breath'].apply(lambda x: 'true' if x==True else x)

df['Shortness_of_breath']=df['Shortness_of_breath'].apply(lambda x: x.lower() if isinstance(x,str) else x)

df['Shortness_of_breath'].value_counts()

sns.countplot(x='Shortness_of_breath', data=df)
plt.show()

df['Headache'].value_counts()

df["Headache"].replace("None", df["Headache"].mode()[0], inplace=True)

df['Headache']=df['Headache'].apply(lambda x: 'false' if x==False else x)
df['Headache']=df['Headache'].apply(lambda x: 'true' if x==True else x)

df['Headache']=df['Headache'].apply(lambda x: x.lower() if isinstance(x,str) else x)

df['Headache'].value_counts()

sns.countplot(x='Headache', data=df)
plt.show()

df['Corona'].value_counts()

df["Corona"].replace("other", df["Corona"].mode()[0], inplace=True)

sns.countplot(x='Corona', data=df)
plt.show()

df['Age_60_above'].value_counts()

# Identify and replace "None" values with the mode
df["Age_60_above"].replace("None", np.nan, inplace=True)
df["Age_60_above"].fillna(df["Age_60_above"].mode()[0], inplace=True)

df['Age_60_above'].value_counts()

sns.countplot(x='Age_60_above', data=df)
plt.show()

sns.countplot(x='Age_60_above', hue='Corona', data=df)

# Show the plot
plt.show()

"""As we seen from the plot most number of positive cases is lies below the age_60 group"""



"""# ** HYPOTHESES TESTING **

Here am using Chi-square tests

Chi-square tests are suitable for analyzing the association between categorical variables. It is used when both the predictor and response variables are categorical.
"""

import pandas as pd
from scipy.stats import chi2_contingency

# Select the relevant columns for analysis
selected_columns = ['Fever', 'Corona']

# Create a contingency table
contingency_table = pd.crosstab(df[selected_columns[0]], df[selected_columns[1]])

# Perform chi-square test
chi2_stat, p_val, dof, expected = chi2_contingency(contingency_table)

# Print the results
print(f"Chi-Square Statistic: {chi2_stat}")
print(f"P-Value: {p_val}")
print(f"Degrees of Freedom: {dof}")
print("Expected Frequencies:\n", expected)

"""The p-value (0.0) is below most common significance levels (e.g., 0.05), indicating that there is a significant association between having 'Fever' and the 'Corona' status. The degrees of freedom (6) depend on the size of the contingency table. In this context, the small p-value suggests that there is evidence to reject the null hypothesis, and you may conclude that the presence of 'Fever' is associated with the 'Corona' status.

**Encoding**
"""

df['Cough_symptoms'] = df['Cough_symptoms'].str.strip().str.lower()
df['Cough_symptoms'] = df['Cough_symptoms'].map({'true': 1, 'false': 0})

df.head(5)

df['Fever'] = df['Fever'].str.strip().str.lower()
df['Fever'] = df['Fever'].map({'true': 1, 'false': 0})

df['Fever'].value_counts()

df['Sore_throat'] = df['Sore_throat'].str.strip().str.lower()
df['Sore_throat'] = df['Sore_throat'].map({'true': 1, 'false': 0})

df['Sore_throat'].value_counts()

df['Shortness_of_breath'] = df['Shortness_of_breath'].str.strip().str.lower()
df['Shortness_of_breath'] = df['Shortness_of_breath'].map({'true': 1, 'false': 0})

df['Shortness_of_breath'].value_counts()

df['Headache'] = df['Headache'].str.strip().str.lower()
df['Headache'] = df['Headache'].map({'true': 1, 'false': 0})

df['Headache'].value_counts()

df['Corona'] = df['Corona'].map({'positive': 1, 'negative': 0})

df['Age_60_above'] = df['Age_60_above'].map({'Yes': 1, 'No': 0})

df.head(5)

df['Sex'].value_counts()

df["Sex"].replace("None", df["Sex"].mode()[0], inplace=True)

df['Sex'].value_counts()

df['Sex'] = df['Sex'].map({'female': 1, 'male': 0})

df.head(5)

df['Known_contact'].value_counts()

"""**Model Training**

**Splitting the data into x and y**
"""

df.isnull().sum()

def data_split(data, ratio):
    np.random.seed(100)
    shuffled = np.random.permutation(len(data))
    test_data_size = int(len(data)*ratio)
    test_data_indices = shuffled[: test_data_size]
    train_data_indices = shuffled[test_data_size :]
    return data.iloc[test_data_indices], data.iloc[train_data_indices]

test_data, train_data = data_split(df, 0.20)

test_data

train_data

"""**Inpendent variables** = 'Cough_symptoms''Fever','Sore_throat','Shortness_of_breath','Headache','Age_above_60','Sex'
**Target variable**="Corona"
"""

x_train = train_data[[	'Cough_symptoms','Fever','Sore_throat','Shortness_of_breath','Headache','Age_60_above','Sex']].to_numpy()

x_train

x_test = test_data[['Cough_symptoms','Fever','Sore_throat','Shortness_of_breath','Headache','Age_60_above','Sex']].to_numpy()

x_test

y_train = train_data[['Corona']].to_numpy().reshape(223079, )
y_test = test_data[['Corona']].to_numpy().reshape(55769, )

y_train

y_test

"""**COMPARATIVE ANALYSIS OF MACHINE LEARNING MODELS**

**LogisticRegression model**
"""

from sklearn.linear_model import LogisticRegression

clf = LogisticRegression()

clf.fit(x_train, y_train)

clf.predict_proba([[ 1, 0, 1, 0, 0,0,0]])

y_pred = clf.predict_proba(x_test)

y_pred

from sklearn.metrics import log_loss

log_loss(y_test, y_pred)

"""A log loss of 0.1611025932733087 is very close to zero, which is generally a good sign in classification problems. Log loss measures the performance of a classification model where the prediction is a probability value between 0 and 1. A lower log loss indicates better performanc"""

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

# Assuming X_train, X_test, y_train, y_test are your training and testing data
#X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)

# Assuming you've trained a Decision Tree model (replace this with your actual model)
logistic_model = LogisticRegression()
logistic_model.fit(x_train, y_train)

# Make predictions on the test set
y_pred =logistic_model.predict(x_test)

# Calculate metrics
conf_matrix = confusion_matrix(y_test, y_pred)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("Confusion Matrix:")##
print(conf_matrix)
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

"""**Decision Tree Classifier**"""

from sklearn.tree import DecisionTreeClassifier

tree_model = DecisionTreeClassifier()

tree_model.fit(x_train, y_train)

tree_predictions = tree_model.predict(x_test)

from sklearn.metrics import accuracy_score

"""**Gini impurity**"""



# Create the model using Gini impurity
tree_model_gini = DecisionTreeClassifier(criterion='gini')

# Train the model
tree_model_gini.fit(x_train, y_train)

# Predictions on the test set
tree_predictions_gini = tree_model_gini.predict(x_test)

# Calculate Gini impurity
gini_impurity = 1 - accuracy_score(y_test, tree_predictions_gini)

tree_model_gini.predict_proba([[ 1, 0, 1, 0, 0,0,0]])

y_pred = tree_model_gini.predict_proba(x_test)

y_pred

log_loss(y_test, y_pred)

"""a log loss value of 0.15915314129844266 is extremely low and close to zero. Log loss is a measure of how well the predicted probabilities match the true probabilities, and a lower log loss indicates better performance."""

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

# Assuming X_train, X_test, y_train, y_test are your training and testing data
#X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)

# Assuming you've trained a Decision Tree model (replace this with your actual model)
tree_model_gini = DecisionTreeClassifier()
tree_model_gini.fit(x_train, y_train)

# Make predictions on the test set
y_pred =tree_model_gini.predict(x_test)

# Calculate metrics
conf_matrix = confusion_matrix(y_test, y_pred)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("Confusion Matrix:")##
print(conf_matrix)
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

"""**Accuracy:**

Accuracy: 95.77%
This metric represents the overall correctness of the model. In your case, the model correctly predicted the class for approximately 95.77% of the instances.
                                                             
**Precision**:

Precision: 85.96%
Precision measures the accuracy of the positive predictions. In your case, when the model predicts the positive class, it is correct about 85.96% of the time.

**Recall (Sensitivity):**

Recall: 24.03%
Recall measures the ability of the model to capture all the relevant instances of the positive class. In your case, the model identified approximately 24.03% of the actual positive instances.

F1 Score:

F1 Score: 37.56%
The F1 Score is the harmonic mean of precision and recall. It provides a balance between precision and recall. In your case, the F1 Score is 37.56%.

In summary, while the model is accurate overall and has good precision, there is room for improvement in capturing more positive instances (increasing recall). The choice of the appropriate metric depends on the specific goals and requirements of the application.

These metrics provide a comprehensive evaluation of the model's performance. High accuracy and precision indicate that the model is making correct positive predictions, but the relatively low recall suggests that the model may not be capturing all positive cases. Depending on the specific requirements of your problem, you may need to balance these metrics or focus on one over the others.

**SVC**
"""

from sklearn.svm import SVC

svm_model = SVC()

svm_model.fit(x_train, y_train)

svm_predictions = svm_model.predict(x_test)

y_pred_train = svm_model.decision_function(x_train)

y_true_train = y_train

from sklearn.metrics import hinge_loss

# Calculate hinge loss on the training data
hinge_loss_train = hinge_loss(y_true_train, y_pred_train)

print(f"Hinge Loss on Training Data: {hinge_loss_train}")

"""A hinge loss close to 0 indicates that the model is making accurate predictions on the training data.
A hinge loss closer to 1 suggests that there are more misclassifications or instances that are not correctly classified by the decision function.
"""

from sklearn.ensemble import GradientBoostingClassifier

gb_model = GradientBoostingClassifier()

gb_model.fit(x_train, y_train)

"""The logistic regression mode and The decision tree models have high accuracy, indicating a good overall performance.

The logistic regression model has a slightly higher recall, meaning it is better at capturing positive instances, though still relatively low.
The decision tree has a slightly higher F1 score, which balances precision and recall.

# **Receiver Operating Characteristic (ROC)  **

The Receiver Operating Characteristic (ROC) curve was generated to assess the performance of our binary classification model comprehensively. By plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold values, the ROC curve provides a visual representation of the trade-off between sensitivity and specificity.

This analysis is crucial as it allows us to understand how well the model distinguishes between positive and negative cases across different decision thresholds. The Area Under the Curve (AUC) of the ROC curve quantifies the model's overall performance, with higher AUC values indicating better discrimination ability.
"""

from sklearn.metrics import roc_curve, auc

fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()

"""Insights from ROC

Trade-off between Sensitivity and Specificity:
    The ROC curve illustrates the trade-off between sensitivity (true positive rate) and specificity (true negative rate). As the threshold for classification changes, sensitivity and specificity may vary inversely.

Diagnostic Accuracy:
    The curve's shape indicates the model's diagnostic accuracy. A curve that hugs the upper left corner of the plot suggests higher accuracy, as it indicates a higher true positive rate and a lower false positive rate across various threshold values.

AUC Interpretation:
    The Area Under the Curve (AUC) quantifies the model's overall performance. An AUC value closer to 1 indicates better discrimination ability, meaning the model can effectively distinguish between positive and negative cases.

Random Classifier Baseline:
    The dashed diagonal line from (0,0) to (1,1) represents the performance of a random classifier. A good model should have an ROC curve above this line, showing superior performance compared to random guessing.

Model Comparison:
    If comparing multiple models, the ROC curves can help visualize and compare their performances. A model with a curve that lies further towards the upper left corner generally outperforms others.

Threshold Selection:
    ROC curves aid in selecting the optimal classification threshold based on the specific needs of the application. Depending on the cost of f
    alse positives versus false negatives, one can adjust the threshold to achieve the desired balance between sensitivity and specificity.
    
These insights help in evaluating the model's performance comprehensively and guide decision-making regarding its deployment and optimization.

**SUMMARY**

This project aimed to analyze COVID-19 data using machine learning techniques. The dataset included information such as age, gender, and pre-existing conditions of patients, along with their COVID-19 test results. The primary objectives were to predict the likelihood of positive COVID-19 cases based on demographic and health-related features and to evaluate the model's performance.

**SQL PART**

**Q1**  Find the number of corona patients who faced shortness of breath.
"""

import duckdb
conn=duckdb.connect()
conn.register('df',df)

result = conn.execute("""
    SELECT COUNT(*) AS num_patients_with_shortness_of_breath
    FROM df
    WHERE Corona = 1 AND Shortness_of_breath = 1;
""").fetchdf()

print(result)

"""**Q2**Find the number of negative corona patients who have fever and sore_throat."""

result = conn.execute("""
    SELECT COUNT(*) AS num_negative_patients_with_fever_and_sore_throat
    FROM df
    WHERE Corona = 0
    AND Fever = 1
    AND Sore_throat = 1;
""").fetchdf()

print(result)

"""**Q3** Group the data by month and rank the number of positive cases."""

result = conn.execute("""
    SELECT
        month AS month,
        COUNT(*) AS num_positive_cases,
        RANK() OVER (ORDER BY COUNT(*) DESC) AS rank
    FROM df
    WHERE Corona = 1
    GROUP BY month
    ORDER BY month;
""").fetchdf()

print(result)

"""**Q4** Find the female negative corona patients who faced cough and headache."""

result = conn.execute("""
    SELECT COUNT(*) AS num_female_negative_patients_with_cough_and_headache
    FROM df
    WHERE Sex = 1
    AND Corona = 0
    AND Cough_symptoms = 1
    AND Headache = 1;
""").fetchdf()

print(result)

"""**Q5** How many elderly corona patients have faced breathing problems?"""

result = conn.execute("""
    SELECT COUNT(*) AS num_elderly_patients_with_breathing_problems
    FROM df
    WHERE Age_60_above = 1
    AND Corona = 1
    AND Breathing_problems = 1;
""").fetchdf()

print(result)

"""**Q6** Which three symptoms were more common among COVID positive patients?


"""

result = conn.execute("""
    SELECT
        SUM(Fever) AS num_positive_with_fever,
        SUM(Cough_symptoms) AS num_positive_with_cough,
        SUM(Shortness_of_breath) AS num_positive_with_shortness_of_breath,
        SUM(Headache) AS num_positive_with_headache,
        SUM(Sore_throat) AS num_positive_with_sore_throat
    FROM df
    WHERE Corona = 1;
""").fetchdf()

# Extracting the top three symptoms based on counts
top_three_symptoms = result.iloc[0].nlargest(3).index.tolist()

print("Top three symptoms among COVID positive patients:")
print(top_three_symptoms)

"""**Q7**Which symptom was less common among COVID negative people?"""

result = conn.execute("""
    SELECT
        SUM(Fever) AS num_negative_with_fever,
        SUM(Cough_symptoms) AS num_negative_with_cough,
        SUM(Shortness_of_breath) AS num_negative_with_shortness_of_breath,
        SUM(Headache) AS num_negative_with_headache,
        SUM(Sore_throat) AS num_negative_with_sore_throat
    FROM df
    WHERE Corona = 1;
""").fetchdf()

# Extracting the symptom with the lowest count
least_common_symptom = result.iloc[0].nsmallest(1).index.tolist()[0]

print("The symptom less common among COVID negative people:")
print(least_common_symptom)

"""**Q8** What are the most common symptoms among COVID positive males whose known contact was abroad?"""

result = conn.execute("""
    SELECT
        SUM(Fever) AS num_positive_male_with_fever,
        SUM(Cough_symptoms) AS num_positive_male_with_cough,
        SUM(Shortness_of_breath) AS num_positive_male_with_shortness_of_breath,
        SUM(Headache) AS num_positive_male_with_headache,
        SUM(Sore_throat) AS num_positive_male_with_sore_throat
    FROM df
    WHERE Corona = 1
        AND Sex = 0
        AND Known_contact = 'abroad';
""").fetchdf()

# Extracting the most common symptom
most_common_symptom = result.iloc[0].idxmax()

print("The most common symptom among COVID positive males with known contact abroad:")
print(most_common_symptom)